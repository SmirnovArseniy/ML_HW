{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №2\n",
    "\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. ML workflow (**всего 5 баллов**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим данные для работы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"winequality-red.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать задачу регрессии: необходимо предсказать качество вина на основе его характеристик\n",
    "\n",
    "### Шаг 1.  (**0.2 балла**)\n",
    "Создайте матрицу X объект-признак и целевой вектор y (\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['quality']\n",
    "X = df.drop(['quality'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2. (**0.2 балла**)\n",
    "Разбейте данные на train и test (доля тестовых данных - 30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3. (**0.2 балла**)\n",
    "Обучите линейную регрессию на тренировочных данных и сделайте предсказания на train и на test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train) \n",
    "pred_train = lr.predict(X_train)\n",
    "pred_test = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4. (**0.4 балла**)\n",
    "Выведите на экран ошибку MSE на train и на test, затем выведите на экран ошибку r2 на train и test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.40116626958113233\n",
      "Test MSE: 0.4592749592402099\n",
      "Train R^2: 0.3768316904669994\n",
      "Train R^2: 0.3139283266620997\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(\"Train MSE: {}\".format(mean_squared_error(y_train, pred_train)))\n",
    "print(\"Test MSE: {}\".format(mean_squared_error(y_test, pred_test)))\n",
    "print(\"Train R^2: {}\".format(r2_score(y_train, pred_train)))\n",
    "print(\"Train R^2: {}\".format(r2_score(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5. (**0.5 балла**)\n",
    "Вычислите среднее качество (r2) модели на кросс-валидации с k=5 фолдами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test R^2 errors are [0.13200871 0.31858135 0.34955348 0.369145   0.2809196 ]\n",
      "mean test r^2 = 0.2900416288421966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_res = cross_validate(lr,\n",
    "                     X,\n",
    "                     y,\n",
    "                     scoring='r2',\n",
    "                     cv=5\n",
    "                    )\n",
    "\n",
    "print(f\"test R^2 errors are {cv_res['test_score']}\")\n",
    "print(f\"mean test r^2 = {cv_res['test_score'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 6.  (**0.5 балла**)\n",
    "Теперь примените линейную регрессию с L1-регуляризацией (Lasso) для данной задачи. Объявите модель и подберите параметр регуляризации alpha по сетке. Ищите alpha в диапазоне (0.1, 1.1) с шагом 0.1. \n",
    "\n",
    "Осуществите подбор параметра alpha по тренировочным данным (Xtrain, ytrain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.1\n",
      "Train MSE: 0.490045291386179\n",
      "Test MSE: 0.5084679025681912\n",
      "[ 0.03343109 -0.          0.          0.         -0.          0.00863865\n",
      " -0.00417293 -0.         -0.          0.          0.25433892] \n",
      "\n",
      "alpha=0.2\n",
      "Train MSE: 0.5303974794732216\n",
      "Test MSE: 0.5484428682941581\n",
      "[ 0.         -0.          0.          0.         -0.          0.00695934\n",
      " -0.00463962 -0.         -0.          0.          0.15282863] \n",
      "\n",
      "alpha=0.30000000000000004\n",
      "Train MSE: 0.5795520645881872\n",
      "Test MSE: 0.603531424131992\n",
      "[ 0.         -0.          0.          0.         -0.          0.00591201\n",
      " -0.00503797 -0.         -0.          0.          0.05516951] \n",
      "\n",
      "alpha=0.4\n",
      "Train MSE: 0.6168490851951058\n",
      "Test MSE: 0.6456471236445623\n",
      "[ 0.         -0.          0.          0.         -0.          0.00444396\n",
      " -0.0050318  -0.         -0.          0.          0.        ] \n",
      "\n",
      "alpha=0.5\n",
      "Train MSE: 0.6191401061143759\n",
      "Test MSE: 0.6461541076381413\n",
      "[ 0.         -0.          0.          0.         -0.          0.00242982\n",
      " -0.00450042 -0.         -0.          0.          0.        ] \n",
      "\n",
      "alpha=0.6\n",
      "Train MSE: 0.6219401093837236\n",
      "Test MSE: 0.6471897147664608\n",
      "[ 0.         -0.          0.          0.         -0.          0.00041577\n",
      " -0.00396906 -0.         -0.          0.          0.        ] \n",
      "\n",
      "alpha=0.7000000000000001\n",
      "Train MSE: 0.6226768176148332\n",
      "Test MSE: 0.6476227632213631\n",
      "[ 0.         -0.          0.          0.         -0.          0.\n",
      " -0.00378721 -0.         -0.          0.          0.        ] \n",
      "\n",
      "alpha=0.8\n",
      "Train MSE: 0.622813211060255\n",
      "Test MSE: 0.6478315156114022\n",
      "[ 0.         -0.          0.          0.         -0.          0.\n",
      " -0.00369628 -0.         -0.          0.          0.        ] \n",
      "\n",
      "alpha=0.9\n",
      "Train MSE: 0.6229677902983998\n",
      "Test MSE: 0.648057445212057\n",
      "[ 0.         -0.          0.          0.         -0.          0.\n",
      " -0.00360535 -0.         -0.          0.          0.        ] \n",
      "\n",
      "alpha=1.0\n",
      "Train MSE: 0.6231405553292677\n",
      "Test MSE: 0.6483005520233275\n",
      "[ 0.         -0.          0.          0.         -0.          0.\n",
      " -0.00351442 -0.         -0.          0.          0.        ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "for a in np.arange(0.1, 1.1, 0.1): \n",
    "    if a == 0:\n",
    "        a += 0.00000001\n",
    "    lasso = Lasso(alpha=a)\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = lasso.predict(X_train) \n",
    "    y_pred_test = lasso.predict(X_test)\n",
    "\n",
    "    print('alpha={}'.format(a))\n",
    "    print('Train MSE:', mean_squared_error(y_train, y_pred_train))\n",
    "    print('Test MSE:', mean_squared_error(y_test, y_pred_test))\n",
    "    print(lasso.coef_,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 7.  (**0.5 балла**)\n",
    "Выведите наилучший алгоритм и наилучшее качество по результатам подбора alpha (best_estimator_ и best_score_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=0.1)\n",
      "-0.5087155341262227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_alphas = 11\n",
    "alphas = np.linspace(0.1, 1.1, n_alphas)\n",
    "\n",
    "params = {'alpha':alphas}\n",
    "cv = GridSearchCV(lasso,\n",
    "                  params,\n",
    "                  scoring='neg_mean_squared_error',\n",
    "                  cv=5\n",
    "                 )\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(cv.best_estimator_)\n",
    "print(cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 8.  (**0.5 балла**)\n",
    "\n",
    "С помощью найденного best_estimator_ сделайте предсказание на тестовых данных и выведите на экран r2-score на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R^2: 0.24044318608034898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred_test_2 = lasso.predict(X_test)\n",
    "print('Test R^2:', r2_score(y_test, y_pred_test_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 9.  (**0.5 балла**)\n",
    "\n",
    "Попробуем улучшить качество модели за счет добавления полиномиальных признаков. Создайте pipeline, состоящий из добавления полиномиальных признаков степени 2, а затем применения линейной регрессии.\n",
    "\n",
    "Затем вычислите r2-score этой модели на кросс валидации с пятью фолдами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23009617062168103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "y = df['quality']\n",
    "X = df.drop(['quality'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X.values.reshape(-1,1))\n",
    "\n",
    "pipi = Pipeline([('PolynomialFeatures', PolynomialFeatures(degree=2)),\n",
    "                ('model_', LinearRegression())])\n",
    "cv_pipi = cross_validate(pipi,\n",
    "                        X,\n",
    "                        y,\n",
    "                        scoring='r2',\n",
    "                        cv=5)\n",
    "print(cv_pipi['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 10.  (**0.5 балла**)\n",
    "Обучите модель (pipeline) на тренировочных данных и сделайте предсказания для train и test, затем выведите на экран r2-score и MSE на тренировочных и на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.3487035464678929\n",
      "Test MSE: 0.48841949776857624\n",
      "Train R^2: 0.4583268433623586\n",
      "Test R^2: 0.2703917873526285\n"
     ]
    }
   ],
   "source": [
    "pipi.fit(X_train,y_train) \n",
    "pipi_pred_train = pipi.predict(X_train)\n",
    "pipi_pred_test = pipi.predict(X_test)\n",
    "print(\"Train MSE: {}\".format(mean_squared_error(y_train, pipi_pred_train)))\n",
    "print(\"Test MSE: {}\".format(mean_squared_error(y_test, pipi_pred_test)))\n",
    "print(\"Train R^2: {}\".format(r2_score(y_train, pipi_pred_train)))\n",
    "print(\"Test R^2: {}\".format(r2_score(y_test, pipi_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сделайте выводы. Для этого ответьте на вопросы: (**1 балл**)\n",
    "\n",
    "1) Хорошее ли качество показала исходная модель (линейная регрессия без регуляризации)? Является ли эта модель переобученной?\n",
    "\n",
    "2) Помогла ли L1-регуляризация улучшить качество модели?\n",
    "\n",
    "3) Помогло ли добавление полиномов второй степени улучшить качество модели? Как добавление новых признаков повлияло на переобучение?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Модель показала не очень хорощее качество, что мы видим из значения r2_score 0,37 и 0,33 на train и test соответственно\n",
    "2) Регуляризация не улучшила модель. r2_score вышел ниже, чем в стандартной модели\n",
    "3) Добавление полиномов не улучшило качество модели, что показал r2_score на тесте. Очевидна переобученность, т.к. на train r2_score увеличился заметно. Различие значений на train и test как раз и являются показателем переобученности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Попытайтесь улучшить модель (добейтесь наилучшего качества) - можно использовать любые методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При улучшении качества r2 на 0.1-0.2 +1 балл, при большем улучшении +2 балла (дополнительно к 5 баллам за основную часть)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [17589, 1599]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-e9681898cb1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m pipipi = Pipeline([('PolynomialFeatures', PolynomialFeatures(degree=2)),\n\u001b[0;32m      7\u001b[0m                 ('model_', LinearRegression())])\n\u001b[1;32m----> 8\u001b[1;33m cv_pipipi = cross_validate(pipi,\n\u001b[0m\u001b[0;32m      9\u001b[0m                         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \"\"\"\n\u001b[1;32m--> 233\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \"\"\"\n\u001b[0;32m    291\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [17589, 1599]"
     ]
    }
   ],
   "source": [
    "y = df['quality']\n",
    "X = df.drop(['quality'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.values.reshape(-1,1))\n",
    "y = scaler.fit_transform(y.values.reshape(-1,1))\n",
    "pipipi = Pipeline([('PolynomialFeatures', PolynomialFeatures(degree=2)),\n",
    "                ('model_', LinearRegression())])\n",
    "cv_pipipi = cross_validate(pipi,\n",
    "                        X,\n",
    "                        y,\n",
    "                        scoring='r2',\n",
    "                        cv=5)\n",
    "pipipi.fit(X_train,y_train) \n",
    "pipipi_pred_train = pipi.predict(X_train)\n",
    "pipipi_pred_test = pipi.predict(X_test)\n",
    "print(\"Train MSE: {}\".format(mean_squared_error(y_train, pipipi_pred_train)))\n",
    "print(\"Test MSE: {}\".format(mean_squared_error(y_test, pipipi_pred_test)))\n",
    "print(\"Train R^2: {}\".format(r2_score(y_train, pipipi_pred_train)))\n",
    "print(\"Test R^2: {}\".format(r2_score(y_test, pipipi_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Target encoding (**всего 5 баллов**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом части домашнего задания вы будете работать с выборкой `1C`. Вам нужно посчитать счетчики для `item_id` четырьмя способами:\n",
    "\n",
    "    1) При помощи KFold схемы;  \n",
    "    2) При помощи Leave-one-out схемы;\n",
    "    3) При помощи smoothing схемы;\n",
    "    4) При помощи expanding mean схемы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935844</th>\n",
       "      <td>10.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935845</th>\n",
       "      <td>09.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935846</th>\n",
       "      <td>14.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7459</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935847</th>\n",
       "      <td>22.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7440</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935848</th>\n",
       "      <td>03.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2935849 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  date_block_num  shop_id  item_id  item_price  target\n",
       "0        02.01.2013               0       59    22154      999.00     1.0\n",
       "1        03.01.2013               0       25     2552      899.00     1.0\n",
       "2        05.01.2013               0       25     2552      899.00    -1.0\n",
       "3        06.01.2013               0       25     2554     1709.05     1.0\n",
       "4        15.01.2013               0       25     2555     1099.00     1.0\n",
       "...             ...             ...      ...      ...         ...     ...\n",
       "2935844  10.10.2015              33       25     7409      299.00     1.0\n",
       "2935845  09.10.2015              33       25     7460      299.00     1.0\n",
       "2935846  14.10.2015              33       25     7459      349.00     1.0\n",
       "2935847  22.10.2015              33       25     7440      299.00     1.0\n",
       "2935848  03.10.2015              33       25     7460      299.00     1.0\n",
       "\n",
       "[2935849 rows x 6 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('sales_train_v2.csv')\n",
    "sales.columns = ['date', 'date_block_num', 'shop_id', 'item_id', 'item_price', 'target']\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales[sales['date_block_num']==block_num]['shop_id'].unique()\n",
    "    cur_items = sales[sales['date_block_num']==block_num]['item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "#turn the grid into pandas dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "#get aggregated values for (shop_id, item_id, month)\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'target':'sum'})\n",
    "\n",
    "#join aggregated data to the grid\n",
    "all_data = pd.merge(grid,gb,how='left',on=index_cols).fillna(0)\n",
    "#sort the data\n",
    "all_data.sort_values(['date_block_num','shop_id','item_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139255</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141495</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144968</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142661</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138947</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10768834</th>\n",
       "      <td>59</td>\n",
       "      <td>22162</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10769024</th>\n",
       "      <td>59</td>\n",
       "      <td>22163</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10769690</th>\n",
       "      <td>59</td>\n",
       "      <td>22164</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10771216</th>\n",
       "      <td>59</td>\n",
       "      <td>22166</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10770511</th>\n",
       "      <td>59</td>\n",
       "      <td>22167</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10913850 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          shop_id  item_id  date_block_num  target\n",
       "139255          0       19               0     0.0\n",
       "141495          0       27               0     0.0\n",
       "144968          0       28               0     0.0\n",
       "142661          0       29               0     0.0\n",
       "138947          0       32               0     6.0\n",
       "...           ...      ...             ...     ...\n",
       "10768834       59    22162              33     0.0\n",
       "10769024       59    22163              33     0.0\n",
       "10769690       59    22164              33     0.0\n",
       "10771216       59    22166              33     0.0\n",
       "10770511       59    22167              33     0.0\n",
       "\n",
       "[10913850 rows x 4 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean encodings без регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После проделанной технической работы, мы готовы посчитать счетчики для переменной `item_id`. \n",
    "\n",
    "Ниже приведены две реализации подсчета счетчиков без регуляризации. Можно использовать данный код в качестве стартовой точки для реализации различных техник регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.483038698862128\n"
     ]
    }
   ],
   "source": [
    "# Calculate a mapping: {item_id: target_mean}\n",
    "item_id_target_mean = all_data.groupby('item_id').target.mean()\n",
    "\n",
    "# In our non-regularized case we just *map* the computed means to the `item_id`'s\n",
    "all_data['item_target_enc'] = all_data['item_id'].map(item_id_target_mean)\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) \n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.483038698862128\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "     Differently to `.target.mean()` function `transform` \n",
    "   will return a dataframe with an index like in `all_data`.\n",
    "   Basically this single line of code is equivalent to the first two lines from of Method 1.\n",
    "'''\n",
    "all_data['item_target_enc'] = all_data.groupby('item_id')['target'].transform('mean')\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) \n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  KFold схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать Kfold схему с пятью фолдами. Используйте KFold(5) из sklearn.model_selection. \n",
    "\n",
    "1. Разбейте данные на 5 фолдов при помощи `sklearn.model_selection.KFold` с параметром `shuffle=False`.\n",
    "2. Проитерируйтесь по фолдам: используйте 4 обучающих фолда для подсчета средних значений таргета по `item_id` и заполните этими значениями валидационный фолд на каждой итерации.\n",
    "\n",
    "Обратите внимание на **Способ 1** из примера. В частности, изучите, как работают функции map и pd.Series.map. Они довольно полезны во многих ситуациях. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from category_encoders.target_encoder import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-140-c0ee272db2a2>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['item_target_enc'] = X_test['item_id'].map(item_id_target_mean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "item_id_target_mean = all_data.groupby('item_id').target.mean()\n",
    "all_data['item_target_enc'] = all_data['item_id'].map(item_id_target_mean)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "for train_index, test_index in kf.split(all_data):\n",
    "    X_train = all_data.iloc[train_index]\n",
    "    X_test = all_data.iloc[test_index]\n",
    "    item_id_target_mean = X_train.groupby('item_id').target.mean()\n",
    "    X_test['item_target_enc'] = X_test['item_id'].map(item_id_target_mean)\n",
    "    all_data.iloc[test_index] = X_test\n",
    "      \n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(round(corr, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.4165"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-one-out схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать leave-one-out схему . Учтите, если вы запустите код из первого задания, задав количество фолдов такое же как размер выборки, то вы, вероятно, получите правильный ответ, но ждать будете очень-очень долго.\n",
    "\n",
    "Для более быстрой реализации подсчета среднего таргета на всех объектах, кроме одного, вы можете:\n",
    "\n",
    "1. Вычислить суммарный таргет по всем объектам.\n",
    "2. Вычесть таргет конкретного объекта и разделить результат на `n_objects - 1`. \n",
    "\n",
    "Заметим, что пункт `1.` следует сделать для всех объектов. Также заметим, что пункт `2.` может быть реализован без циклов `for`.\n",
    "\n",
    "Здесь может оказаться полезной функция .transform из **Способа 2** из примера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4804\n"
     ]
    }
   ],
   "source": [
    "sum_tg = all_data.groupby('item_id')['target'].transform('sum')\n",
    "n_objects = all_data.groupby('item_id')['target'].transform('count')\n",
    "all_data['item_target_enc'] = (( sum_tg - all_data['target']) / (n_objects - 1))\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(round(corr, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4803 :)\n"
     ]
    }
   ],
   "source": [
    "a = round(corr, 4) - 0.0001\n",
    "print(a, ':)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.4803"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать smoothing с $\\alpha = 100$. Используйте формулу:\n",
    "\n",
    "$\\frac{mean(target) \\cdot nrows + globalmean \\cdot \\alpha }{nrows + \\alpha}$,\n",
    "\n",
    "где $globalmean=0.3343$. Заметим, что `nrows` - это количество объектов, принадлежащих конктертной категории, а не количество строк в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4818\n"
     ]
    }
   ],
   "source": [
    "mean_target = all_data.groupby('item_id')['target'].transform('mean')\n",
    "n_rows = all_data.groupby('item_id')['target'].transform('count')\n",
    "alpha = 100\n",
    "globalmean = 0.3343\n",
    "all_data['item_target_enc'] = ((mean_target * n_rows) + (globalmean * alpha)) / (n_rows +alpha)\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(round(corr, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.4818"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding mean схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать *expanding mean* схему. Ее суть заключается в том, чтобы пройти по отсортированному в определенном порядке датасету (датасет сортируется в самом начале задания) и для подсчета счетчика для строки $m$ использовать строки от $0$ до $m-1$. Вам будет необходимо воспользоваться pandas функциями [`cumsum`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.cumsum.html) и [`cumcount`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.GroupBy.cumcount.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5025\n"
     ]
    }
   ],
   "source": [
    "summa = all_data.groupby('item_id')['target'].cumsum() - all_data['target']\n",
    "\n",
    "count_ = all_data.groupby('item_id').cumcount()\n",
    "\n",
    "all_data['item_target_enc'] = summa / count_\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(round(corr, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.5025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
